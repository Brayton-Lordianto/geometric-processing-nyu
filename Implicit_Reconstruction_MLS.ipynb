{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: number expected\n"
     ]
    }
   ],
   "source": [
    "![](assets/mesh_reconstruction.mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install libigl\n",
    "%pip install git+https://github.com/skoch9/meshplot.git\n",
    "%pip install ipywidgets\n",
    "%pip install pythreejs\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import igl\n",
    "import meshplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, display\n",
    "meshplot.offline()\n",
    "class HTML_Plotter(): \n",
    "    def plot(self, data, faces=None, c=None, shading=None): \n",
    "        p = meshplot.plot(data, faces, c=c, shading=shading, return_plot=True)\n",
    "        html = p.to_html(imports=True, html_frame=True)\n",
    "        display(HTML(html))\n",
    "        return p\n",
    "        # p.save(\"temp.html\")\n",
    "        # display(IFrame(src=\"./temp.html\", width=1500, height=1500))\n",
    "mp = HTML_Plotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscallenous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fprint(arr): \n",
    "    with np.printoptions(threshold=np.inf): print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floating_point_precision = 1e-8\n",
    "zero_result_tolerance = 1e-6 # the tolerance for the zero result of the function, which will determine if the point is in the function \n",
    "large_positive_number = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wendland constant and resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_wendland = 0.15\n",
    "luigi_wendland = 0.08\n",
    "wendland_factor = cat_wendland\n",
    "def wendlandFactor(k): \n",
    "    global wendland_factor\n",
    "    return wendland_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_resolution = 20\n",
    "luigi_resolution = 12\n",
    "resolution = cat_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_cat(): \n",
    "    global wendland_factor, resolution\n",
    "    wendland_factor = cat_wendland\n",
    "    resolution = cat_resolution\n",
    "def setup_luigi(): \n",
    "    global wendland_factor, resolution\n",
    "    wendland_factor = luigi_wendland\n",
    "    resolution = luigi_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wendlandRadius(k, pcbbox_diag): \n",
    "    return wendlandFactor(k) * pcbbox_diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v_f_ni(name_of_mesh):\n",
    "    v, f = igl.read_triangle_mesh(name_of_mesh)\n",
    "    v /= 10\n",
    "    ni = igl.per_vertex_normals(v, f)\n",
    "    return v, f, ni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLS constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomialTerms(k):\n",
    "    return 1 if k == 0 else (4 if k == 1 else 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boundary box conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much of the tight bounding box diagonal should the bounding box be enlarged by\n",
    "bounds_enlargement_factor = 0.05\n",
    "\n",
    "#how much of the tight bounding box diagonal should the initial epsilon be\n",
    "initial_eps_factor = 0.01\n",
    "\n",
    "# to ensure offsetted points are within the enlarged bounding box, we need the initial epsilon factor to be less than the bounds enlargement factor\n",
    "assert(initial_eps_factor < bounds_enlargement_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_eps(bounds):\n",
    "    _, _, pcbbox_diag, _ = bounds\n",
    "    return initial_eps_factor * pcbbox_diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Hashing Constant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Should grid_spacing be constant or variable depending on resolution? \n",
    "\n",
    "previous implemenation: grid_spacing = pcbbox_diag // resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_in_spatial_grid = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh_bounds(vertices):\n",
    "    # initial tight constraint\n",
    "    pcbbox_min = np.min(vertices, axis=0)\n",
    "    pcbbox_max = np.max(vertices, axis=0)\n",
    "    pcbbox_diag = np.linalg.norm(pcbbox_max - pcbbox_min)\n",
    "    \n",
    "    # enlarge the bounding box \n",
    "    pcbbox_min -= bounds_enlargement_factor * pcbbox_diag\n",
    "    pcbbox_max += bounds_enlargement_factor * pcbbox_diag\n",
    "    pcbbox_diag = np.linalg.norm(pcbbox_max - pcbbox_min)\n",
    "\n",
    "    grid_spacing = (pcbbox_max - pcbbox_min) / cells_in_spatial_grid\n",
    "    return pcbbox_min, pcbbox_max, pcbbox_diag, grid_spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tet Grid (Provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utility function to generate a tet grid\n",
    "# n is a 3-tuple with the number of cell in every direction\n",
    "# mmin/mmax are the grid bounding box corners\n",
    "\n",
    "def tet_grid(n, mmin, mmax):\n",
    "    nx = n[0]\n",
    "    ny = n[1]\n",
    "    nz = n[2]\n",
    "    \n",
    "    delta = mmax-mmin\n",
    "    \n",
    "    deltax = delta[0]/(nx-1)\n",
    "    deltay = delta[1]/(ny-1)\n",
    "    deltaz = delta[2]/(nz-1)\n",
    "    \n",
    "    T = np.zeros(((nx-1)*(ny-1)*(nz-1)*6, 4), dtype=np.int64)\n",
    "    V = np.zeros((nx*ny*nz, 3))\n",
    "\n",
    "    mapping = -np.ones((nx, ny, nz), dtype=np.int64)\n",
    "\n",
    "\n",
    "    index = 0\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            for k in range(nz):\n",
    "                mapping[i, j, k] = index\n",
    "                V[index, :] = [i*deltax, j*deltay, k*deltaz]\n",
    "                index += 1\n",
    "    assert(index == V.shape[0])\n",
    "    \n",
    "    tets = np.array([\n",
    "        [0,1,3,4],\n",
    "        [5,2,6,7],\n",
    "        [4,1,5,3],\n",
    "        [4,3,7,5],\n",
    "        [3,1,5,2],\n",
    "        [2,3,7,5]\n",
    "    ])\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(nx-1):\n",
    "        for j in range(ny-1):\n",
    "            for k in range(nz-1):\n",
    "                indices = [\n",
    "                    (i,   j,   k),\n",
    "                    (i+1, j,   k),\n",
    "                    (i+1, j+1, k),\n",
    "                    (i,   j+1, k),\n",
    "\n",
    "                    (i,   j,   k+1),\n",
    "                    (i+1, j,   k+1),\n",
    "                    (i+1, j+1, k+1),\n",
    "                    (i,   j+1, k+1),\n",
    "                ]\n",
    "                \n",
    "                for t in range(tets.shape[0]):\n",
    "                    tmp = [mapping[indices[ii]] for ii in tets[t, :]]\n",
    "                    T[index, :]=tmp\n",
    "                    index += 1\n",
    "                    \n",
    "    assert(index == T.shape[0])\n",
    "    \n",
    "    V += mmin\n",
    "    return V, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Step 1 : Setting up the Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regShading = {\"point_size\": 1,\"width\": 800, \"height\": 800}\n",
    "def shadingPoints(pointsize):\n",
    "    return {\"point_size\": pointsize,\"width\": 800, \"height\": 800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_length(vectors):\n",
    "    return np.linalg.norm(vectors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_point(point, points): \n",
    "    # vector of distances \n",
    "    differences = points - point \n",
    "    distances =  vectors_length(differences)\n",
    "    \n",
    "    # if zero, set it to infinity - exclude the point itself \n",
    "    distances[np.where(np.abs(distances) < floating_point_precision)] = np.inf \n",
    "    \n",
    "    # find the index of the closest by using argmin \n",
    "    closest_index = np.argmin(distances)\n",
    "    return points[closest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPoint(point, points): \n",
    "    if points.size == 0: return np.array([point])\n",
    "    return np.append(points, [point], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a global correct epsilon, then getting the total points with offsetted points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(v, ni, initialEps):\n",
    "    # the ordering of totalVertices is [v, v+eps*ni, v-eps*ni]\n",
    "    n = len(v)\n",
    "    eps = initialEps \n",
    "    totalVertices = copy.deepcopy(v)\n",
    "    \n",
    "    # get epsilon from a single offset type -- piPlus or piMinus\n",
    "    # get_offset_point is a function that takes a point and epsilon normal and spits out an updated offset point\n",
    "    def get_eps_partially(v, ni, eps, totalVertices, get_offset_point):\n",
    "        for i in range(n): \n",
    "            pt = v[i]\n",
    "            norm = ni[i]\n",
    "            epsNormal = eps * norm\n",
    "            pi = get_offset_point(pt, epsNormal)\n",
    "            totalVertices = addPoint(pi, totalVertices)\n",
    "            while not np.array_equal(find_closest_point(pi, totalVertices), pt): \n",
    "                totalVertices = totalVertices[:-1]\n",
    "                eps /= 2\n",
    "                pi = get_offset_point(pt, eps * norm)\n",
    "                totalVertices = addPoint(pi, totalVertices)\n",
    "        return eps, totalVertices\n",
    "    \n",
    "    # get eps from both piPlus and piMinus\n",
    "    eps, totalVertices  = get_eps_partially(v, ni, eps, totalVertices, \n",
    "                                            get_offset_point=lambda pt, epsNormal: pt + epsNormal)\n",
    "    eps, _              = get_eps_partially(v, ni, eps, totalVertices, \n",
    "                                            get_offset_point=lambda pt, epsNormal: pt - epsNormal)\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_vertices(v, ni, eps):\n",
    "    epsPos = np.array([])\n",
    "    epsNeg = np.array([])\n",
    "    totalVertices = copy.deepcopy(v)\n",
    "\n",
    "    # now do a single run for the new eps, to get the epsPos and epsNeg\n",
    "    for i in range(len(v)): \n",
    "        pt = v[i]\n",
    "        norm = ni[i]\n",
    "        epsNormal = eps * norm\n",
    "        piPlus = pt + epsNormal\n",
    "        piMinus = pt - epsNormal\n",
    "        \n",
    "        epsPos = addPoint(piPlus, epsPos)\n",
    "        epsNeg = addPoint(piMinus, epsNeg)\n",
    "        \n",
    "    # totalvertices being v + epsPos + epsNeg\n",
    "    totalVertices = copy.deepcopy(v)\n",
    "    totalVertices = np.append(totalVertices, epsPos, axis=0)\n",
    "    totalVertices = np.append(totalVertices, epsNeg, axis=0)\n",
    "    return totalVertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting colors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRGB_colors(total_points_size):\n",
    "    colors = np.zeros((total_points_size,3))\n",
    "    one_third = total_points_size // 3\n",
    "    colors[:one_third,0] = 1\n",
    "    colors[one_third:2*one_third,1] = 1\n",
    "    colors[2*one_third:,2] = 1\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with the offsetted points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_offsetted_points(v, ni, pointSize):\n",
    "    bounds = mesh_bounds(v)\n",
    "    initialEps = get_initial_eps(bounds)\n",
    "    eps = get_eps(v, ni, initialEps)\n",
    "    totalVertices = get_total_vertices(v, ni, eps) \n",
    "    colors = getRGB_colors(len(totalVertices))\n",
    "    return mp.plot(totalVertices, c=colors, shading=shadingPoints(pointSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mesh_with_offsetted_points(name_of_mesh, pointSize=4): \n",
    "    v, _, ni = get_v_f_ni(name_of_mesh)\n",
    "    return plot_with_offsetted_points(v, ni, pointSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Output\n",
    "\n",
    " * Plot of the provided point cloud shaded with green, blue, and red dots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Green is outside, red is on the surface, and blue is inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshplot.offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_luigi()\n",
    "plot_mesh_with_offsetted_points(\"data/luigi.off\", pointSize=1)\n",
    "setup_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_with_offsetted_points(\"data/cat.off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: why does it look so close? \n",
    "\n",
    "Answer from Professor: It depends on your epsilon. You can choose a smaller and bigger beginnning epsilon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Use MLS interpolation to extend to function `f`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a grid sampling the 3D space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is taken care of within the plotting function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closest points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Important**: explicitty write a function `closest_points(point, points, h)` that retreives the indices all points in `points` that are at distance less than `h` from `point`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_points(point, points, h): \n",
    "    # filter the points that are within the radius\n",
    "    differences = points - point\n",
    "    distances =  vectors_length(differences)\n",
    "    indices = np.where(distances < h)\n",
    "    \n",
    "    # `indices` is a tuple, so we need to get the first element, which is the array of indices\n",
    "    return indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with Wendland Radius using closestpoints \n",
    "\n",
    "Goal: Get a correct wendland radius where, for all points, the number of closest points to all the points is more or equal to twice the number of polynomial terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: (This was run on the 'cat' point cloud then cross checked with the 'luigi' point cloud)\n",
    "\n",
    "Let the left expression be the wendland radius experimented on.\n",
    "Let conditions on the right be whether or not there are 2 * polynomial terms closest points to the point at the given radius.\n",
    "\n",
    "**k = 0**\n",
    "\n",
    "0.004 * pcbbox -> False\n",
    "\n",
    "0.005 * pcbbox -> True\n",
    "\n",
    "So, I tried 0.006 * pcbbox\n",
    "\n",
    "**k = 1**\n",
    "\n",
    "0.08 * pcbbox -> False\n",
    "\n",
    "0.09 * pcbbox -> True\n",
    "\n",
    "So, I tried 0.1 * pcbbox\n",
    "\n",
    "**k = 2**\n",
    "\n",
    "0.12 * pcbbox -> False \n",
    "\n",
    "0.13 * pcbbox -> True\n",
    "\n",
    "So, I tried 0.14 * pcbbox \n",
    "\n",
    "\n",
    "In the end, I used 0.15 as the factor, and you can see this result in the [Step 5 Section](#step-5-extracting-the-surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_with_wendland(experimentalWendlandFactor, experimentalK, points, ni):\n",
    "    bounds = mesh_bounds(points)\n",
    "    initialEps = get_initial_eps(bounds)\n",
    "    _, _, pcbbox_diag, _ = bounds\n",
    "    experimentalRadius = experimentalWendlandFactor * pcbbox_diag\n",
    "    eps = get_eps(points, ni, initialEps)\n",
    "    totalVertices = get_total_vertices(points, ni, eps) \n",
    "    \n",
    "    def experimentClosestPoints(point): \n",
    "        # check how many points are within the radius\n",
    "        indices = closest_points(point, totalVertices, experimentalRadius)\n",
    "        return len(indices)\n",
    "    a = np.apply_along_axis(experimentClosestPoints, axis=1, arr=totalVertices)\n",
    "    return (a > 2 * polynomialTerms(experimentalK)).all()\n",
    "\n",
    "def experiment_with_wendland_on_mesh(name_of_mesh, experimentalWendlandFactor, experimentalK):\n",
    "    v, _, ni = get_v_f_ni(name_of_mesh)\n",
    "    return experiment_with_wendland(experimentalWendlandFactor, experimentalK, v, ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_with_wendland_on_mesh(\"data/cat.off\", experimentalWendlandFactor=0.14, experimentalK=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLS Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get wendland matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wendland(point, radius): \n",
    "    d = np.linalg.norm(point)\n",
    "    if d >= radius: return 0\n",
    "    return ((1 - d / radius) ** 4) * (4 * d / radius + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wendland matrix \n",
    "def W(x, radius, closeByPoints, total_points): \n",
    "    # compute diagonal matrix\n",
    "    n = total_points.shape[0]\n",
    "    indices = closeByPoints\n",
    "    values = np.zeros((n))\n",
    "    for i in indices: \n",
    "        values[i] = wendland(x - total_points[i], radius)\n",
    "    diagonal = np.diag(values)\n",
    "    return diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get Basis Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_k(total_points, k): \n",
    "    n = total_points.shape[0]\n",
    "    ones = np.ones((n, 1))\n",
    "    if k == 0: return ones\n",
    "    \n",
    "    x, y, z = total_points[:,0], total_points[:,1], total_points[:,2]\n",
    "    if k == 1: \n",
    "        B = np.empty((0,4))\n",
    "        for i in range(n): B = np.vstack([B, [1, x[i], y[i], z[i]]])\n",
    "        return B\n",
    "    \n",
    "    xy, xz, yz = x * y, x * z, y * z\n",
    "    xx, yy, zz = x ** 2, y ** 2, z ** 2\n",
    "    if k == 2: \n",
    "        B = np.empty((0,10))\n",
    "        for i in range(n): B = np.vstack([B, [1, x[i], y[i], z[i], xy[i], xz[i], yz[i], xx[i], yy[i], zz[i]]])\n",
    "        return B\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get `d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 1/3 are 0, next 1/3 are eps, last 1/3 are -eps\n",
    "def get_d(total_points, eps): \n",
    "    d = np.zeros((total_points.shape[0]))\n",
    "    one_third = total_points.shape[0] // 3\n",
    "    d[one_third:2*one_third] = eps\n",
    "    d[2*one_third:] = -eps\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BtWxB(B, BtWx): \n",
    "    return BtWx @ B\n",
    "\n",
    "def BtWxd(BtWx, d): \n",
    "    return BtWx @ d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveA(x, total_points, radius, basis, d, closeByPoints): \n",
    "    B = basis\n",
    "    W_matrix = W(x, radius, closeByPoints, total_points)\n",
    "    BtWx = B.T @ W_matrix\n",
    "    \n",
    "    A = BtWxB(B, BtWx)\n",
    "    b = BtWxd(BtWx, d)\n",
    "    return np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFxValue(pt, weights, k):\n",
    "    one = 1 \n",
    "    if k == 0: \n",
    "        aone = weights[0]\n",
    "        return aone * one\n",
    "    \n",
    "    x, y, z = pt[0], pt[1], pt[2]\n",
    "    if k == 1: \n",
    "        aone, ax, ay, az = weights\n",
    "        return aone * one + ax * x + ay * y + az * z\n",
    "    \n",
    "    xy, xz, yz,xsq, ysq, zsq = x * y, x * z, y * z, x ** 2, y ** 2, z ** 2\n",
    "    if k == 2:\n",
    "        aone, ax, ay, az, axy, axz, ayz, axx, ayy, azz = weights\n",
    "        return (aone * one + ax * x + ay * y + az * z + axy * xy + axz * xz + ayz * yz + axx * xsq + ayy * ysq + azz * zsq)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLS Final - Solving for `f`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLS(pt, total_points, radius, basis, d, k): \n",
    "    # check that there are enough points around it to make a MLS fit \n",
    "    closeByPoints = closest_points(pt, total_points, radius)\n",
    "    if len(closeByPoints) < 2 * polynomialTerms(k): \n",
    "        return large_positive_number # return a large number to indicate that the point is not outside the surface\n",
    "    \n",
    "    # first get coefficients\n",
    "    a = solveA(pt, total_points, radius, basis, d, closeByPoints)\n",
    "    \n",
    "    # solve for the value \n",
    "    value = getFxValue(pt, a, k)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `f` for all points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_implicit_function(total_points, eps, bounds, k=2, plot=True, pointsSize=4): \n",
    "    pcbbox_min, pcbbox_max, pcbbox_diag, _ = bounds\n",
    "    x, T = tet_grid((resolution,resolution,resolution), \n",
    "                pcbbox_min - 0.05 * pcbbox_diag, pcbbox_max + 0.05 * pcbbox_diag)\n",
    "    wendland_radius = wendlandRadius(k, pcbbox_diag)\n",
    "    basis, d = B_k(total_points, k), get_d(total_points, eps)\n",
    "    indicators = np.apply_along_axis(\n",
    "        lambda point: MLS(point, total_points, wendland_radius, basis, d, k), \n",
    "        axis=1, arr=x)\n",
    "    \n",
    "    colors = np.zeros_like(indicators)\n",
    "    colors[indicators >= 0] = 1\n",
    "    colors[indicators < 0] = -1\n",
    "    if plot: mp.plot(x, c=colors, shading={\"point_size\": pointsSize,\"width\": 800, \"height\": 800})\n",
    "    else: return x, T, indicators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot points - no extraction yet\n",
    "def plot_mesh_points(name_of_mesh, k=2, plot=True, pointsSize=4): \n",
    "    v, _, ni = get_v_f_ni(name_of_mesh)\n",
    "    bounds = mesh_bounds(v)\n",
    "    initialEps = get_initial_eps(bounds)\n",
    "    eps = get_eps(v, ni, initialEps)\n",
    "    total_points = get_total_vertices(v, ni, eps)\n",
    "    return plot_implicit_function(total_points, eps, bounds, k, plot, pointsSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Output of Section\n",
    "\n",
    "* Plot of the grid points x colored according of being inside or outside the input cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion: There are some noise/artifacts around the point cloud, but the shape of the point cloud is captured. As `k` increases, it seems there are more artifacts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_points(\"data/cat.off\", k=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_points(\"data/cat.off\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_points(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Implementing a spatial index to accelerate neighbor calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no required output of this section. Refer to [this section](#additional-reports) for evidence of the spatial acceleration data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Hash of all points and place points into the bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid spacing should be also [x,y,z] representing the spacing for each dimension\n",
    "def get_spatial_index(point, pcbbox_min, grid_spacing): \n",
    "    return ((point - pcbbox_min) // grid_spacing).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_spatial_hash(point, associated_index, spatial_hash, bounds): \n",
    "    pcbbox_min, _, _, grid_spacing = bounds\n",
    "    x, y, z = get_spatial_index(point, pcbbox_min, grid_spacing)\n",
    "    spatial_hash[x][y][z].append(associated_index)\n",
    "    return spatial_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a hash of the indices of the points\n",
    "def get_spatial_grid(points, bounds):\n",
    "    x_s, y_s, z_s = cells_in_spatial_grid, cells_in_spatial_grid, cells_in_spatial_grid\n",
    "    spatial_hash = np.empty((x_s, y_s, z_s, 0)).tolist()\n",
    "    for index in range(len(points)): \n",
    "        add_to_spatial_hash(points[index], index, spatial_hash, bounds)\n",
    "    return spatial_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes the last element in the spatial bin where the point is located\n",
    "def remove_last_from_spatial_hash(point, spatial_hash, bounds): \n",
    "    pcbbox_min, _, _, grid_spacing = bounds\n",
    "    x, y, z = get_spatial_index(point, pcbbox_min, grid_spacing)\n",
    "    spatial_hash[x][y][z] = spatial_hash[x][y][z][:-1]\n",
    "    return spatial_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the set of points within a certain distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_indices(point, h, spatial_hash, bounds): \n",
    "    # get the min and max cells \n",
    "    # you have to add 1 to the max cell because you want to range from min to max inclusive\n",
    "    pcbbox_min, _, _, grid_spacing = bounds\n",
    "    p_h_min, p_h_max = get_spatial_index(point - h, pcbbox_min, grid_spacing), get_spatial_index(point + h, pcbbox_min, grid_spacing) + 1\n",
    "    xmin, ymin, zmin = p_h_min\n",
    "    xmax, ymax, zmax = p_h_max\n",
    "    \n",
    "    # clamp cell values to be within the grid\n",
    "    x_s, y_s, z_s = cells_in_spatial_grid, cells_in_spatial_grid, cells_in_spatial_grid\n",
    "    xmin, ymin, zmin, xmax, ymax, zmax = max(0, xmin), max(0, ymin), max(0, zmin), min(x_s, xmax), min(y_s, ymax), min(z_s, zmax) \n",
    "    \n",
    "    # get as indices, using list comprehension\n",
    "    filtered_indices =  [element \n",
    "                                for x in range(xmin, xmax) \n",
    "                                for y in range(ymin, ymax)\n",
    "                                for z in range(zmin, zmax)\n",
    "                                for element in spatial_hash[x][y][z]]\n",
    "    return np.array(filtered_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization for `find_closest_point` and `get_eps`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I did not change `find_closest_point` but rather `get_eps` when finding the closest point. TA said this is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_point_accelerated(point, points, epsNorm=None, spatial_hash=None, bounds=None):\n",
    "    accelerated_mode = spatial_hash is not None and bounds is not None and epsNorm is not None\n",
    "    if accelerated_mode: \n",
    "        # enlarge eps a bit \n",
    "        # since we just added point, which is epsNorm away from the original point, there is at least one point within the l2 distance of epsNorm\n",
    "        epsNorm *= 1.01\n",
    "        radial_distance = np.linalg.norm(epsNorm)\n",
    "        filtered_indices = get_filtered_indices(point, radial_distance, spatial_hash, bounds)\n",
    "        points = points[filtered_indices]\n",
    "    \n",
    "    # vector of distances \n",
    "    differences = points - point \n",
    "    distances =  vectors_length(differences)\n",
    "    \n",
    "    # if zero, set it to infinity - exclude the point itself \n",
    "    distances[np.where(np.abs(distances) < floating_point_precision)] = np.inf \n",
    "    \n",
    "    # find the index of the closest by using argmin \n",
    "    closest_index = np.argmin(distances)\n",
    "    \n",
    "    return points[closest_index]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in addition to before, we add offsetted points into the spatial hash \n",
    "# and we also call an accelerated find closest points \n",
    "def get_eps_acccelerated(v, ni, initialEps, bounds, initial_spatial_hash):\n",
    "    # the ordering of totalVertices is [v, v+eps*ni, v-eps*ni]\n",
    "    n = len(v)\n",
    "    eps = initialEps \n",
    "    totalVertices = copy.deepcopy(v)\n",
    "    spatial_hash = initial_spatial_hash\n",
    "    \n",
    "    # get epsilon from a single offset type -- piPlus or piMinus\n",
    "    # get_offset_point is a function that takes a point and epsilon normal and spits out an updated offset point\n",
    "    # get_associated_index is a function that takes an original index, and returns the associated index in the totalVertices\n",
    "    def get_eps_partially(v, ni, eps, totalVertices, bounds, spatial_hash, get_offset_point, get_associated_index):\n",
    "        for i in range(len(v)): \n",
    "            pt = v[i]\n",
    "            norm = ni[i]\n",
    "            epsNormal = eps * norm\n",
    "            pi = get_offset_point(pt, epsNormal)\n",
    "            \n",
    "            totalVertices = addPoint(pi, totalVertices)\n",
    "            associated_index = get_associated_index(i)\n",
    "            spatial_hash = add_to_spatial_hash(pi, associated_index, spatial_hash, bounds)\n",
    "            while not np.array_equal(find_closest_point(pi, totalVertices), pt): \n",
    "                # remove the old point \n",
    "                totalVertices = totalVertices[:-1]\n",
    "                spatial_hash = remove_last_from_spatial_hash(pi, spatial_hash, bounds)\n",
    "                \n",
    "                # get the new point\n",
    "                eps /= 2\n",
    "                pi = get_offset_point(pt, eps * norm)\n",
    "                \n",
    "                # add the new point\n",
    "                totalVertices = addPoint(pi, totalVertices)\n",
    "                associated_index = get_associated_index(i)\n",
    "                spatial_hash = add_to_spatial_hash(pi, associated_index, spatial_hash, bounds)\n",
    "        return eps, totalVertices\n",
    "    \n",
    "    # get eps from both piPlus and piMinus\n",
    "    eps, totalVertices  = get_eps_partially(v, ni, eps, totalVertices, bounds, spatial_hash, \n",
    "                                            get_offset_point=    lambda pt, epsNormal: pt + epsNormal, \n",
    "                                            get_associated_index=lambda i: i + n)\n",
    "    eps, _              = get_eps_partially(v, ni, eps, totalVertices, bounds, spatial_hash,\n",
    "                                            get_offset_point=    lambda pt, epsNormal: pt - epsNormal,\n",
    "                                            get_associated_index=lambda i: i + 2 * n)\n",
    "    return eps, spatial_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization for `closest_point` and `MLS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closest Points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_points_accelerated(point, points, h, bounds, spatial_hash): \n",
    "    #  get the filtered points within cells of the spatial hash within the radius\n",
    "    filtered_indices = get_filtered_indices(point, h, spatial_hash, bounds)\n",
    "    if filtered_indices.shape[0] == 0: return np.array([])\n",
    "    points = points[filtered_indices]\n",
    "    \n",
    "    # further filtering\n",
    "    # filter the points that are within the radius\n",
    "    differences = points - point\n",
    "    distances =  vectors_length(differences)\n",
    "    indices = np.where(distances < h)\n",
    "    \n",
    "    # remap the indices to the original indices\n",
    "    indices = filtered_indices[indices]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing of variables down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLS_accelerated(pt, total_points, radius, basis, d, bounds, spatial_hash, k): \n",
    "    # check that there are enough points around it to make a MLS fit \n",
    "    closeByPoints = closest_points_accelerated(pt, total_points, radius, bounds, spatial_hash)\n",
    "    if len(closeByPoints) < 2 * polynomialTerms(k): \n",
    "        return large_positive_number # return a large number to indicate that the point is not outside the surface\n",
    "    \n",
    "    # first get coefficients\n",
    "    a = solveA(pt, total_points, radius, basis, d, closeByPoints)\n",
    "    \n",
    "    # solve for the value \n",
    "    value = getFxValue(pt, a, k)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_implicit_function_accelerated(total_points, eps, bounds, spatial_hash, k=2, plot=True, pointsSize=4):\n",
    "    # all the same except for the addition of spatial_hash\n",
    "    pcbbox_min, pcbbox_max, pcbbox_diag, _ = bounds\n",
    "    x, T = tet_grid((resolution,resolution,resolution), \n",
    "                pcbbox_min - 0.05 * pcbbox_diag, pcbbox_max + 0.05 * pcbbox_diag)\n",
    "    wendland_radius = wendlandRadius(k, pcbbox_diag)\n",
    "    basis, d = B_k(total_points, k), get_d(total_points, eps)\n",
    "    indicators = np.apply_along_axis(\n",
    "        lambda point: MLS_accelerated(point, total_points, wendland_radius, basis, d, bounds, spatial_hash, k), \n",
    "        axis=1, arr=x)\n",
    "    \n",
    "    colors = np.zeros_like(indicators)\n",
    "    colors[indicators >= 0] = 1\n",
    "    colors[indicators < 0] = -1\n",
    "    if plot: mp.plot(x, c=colors, shading={\"point_size\": pointsSize,\"width\": 800, \"height\": 800})\n",
    "    else: return x, T, indicators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot points - no extraction yet\n",
    "def plot_mesh_points_accelerated(name_of_mesh, k=2, plot=True, pointsSize=4): \n",
    "    v, _, ni = get_v_f_ni(name_of_mesh)\n",
    "    bounds = mesh_bounds(v)\n",
    "    initialEps = get_initial_eps(bounds)\n",
    "    spatial_hash = get_spatial_grid(v, bounds)\n",
    "    eps, spatial_hash = get_eps_acccelerated(v, ni, initialEps, bounds, initial_spatial_hash=spatial_hash)\n",
    "    total_points = get_total_vertices(v, ni, eps)\n",
    "    return plot_implicit_function_accelerated(total_points, eps, bounds, spatial_hash, k, plot, pointsSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Using a non-axis-aligned grid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explanation of pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I never learned about PCA before, so this was an example I tried to really understand it. Accordingly, I applied the 2D understanding of it to a point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how PCA works\n",
    "# here's the plotting as well \n",
    "values = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "pca = PCA(n_components=2)\n",
    "transformedValues = pca.fit_transform(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the blue are the original points, and the orange are the transformed points. It makes the transformed points have the highest variance on the x axis, which is going to be what we want for the bounding box of the point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(values[:, 0], values[:, 1])\n",
    "plt.scatter(transformedValues[:, 0], transformedValues[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply PCA transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I directly apply it to the vertices right when reading them from the mesh. This ensures the normals are also transformed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca_transform(points): \n",
    "    pca = PCA(n_components=3)\n",
    "    return pca.fit_transform(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as before, except with PCA applied\n",
    "def get_v_f_ni(name_of_mesh):\n",
    "    v, f = igl.read_triangle_mesh(name_of_mesh)\n",
    "    v /= 10\n",
    "    v = apply_pca_transform(v)\n",
    "    ni = igl.per_vertex_normals(v, f)\n",
    "    return v, f, ni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test it using just points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly, the luigi points are aligned. The next section shows this in the grid, which more clearly shows that it is aligned as the bounds are minimal and axis aligned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, f, ni = get_v_f_ni(\"data/luigi.off\")\n",
    "mp.plot(v, shading={\"point_size\": 5,\"width\": 800, \"height\": 800})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the grid with nodes colored according to their implicit function values. There is not a noticable speedup, but the next sub-section talks about the speedup. Here, at least, you can see that the results are the same visually. Please change `resolution` under the `Spatial Hashing Constants` section if it loads too slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_points(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_points_accelerated(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I recommend changing resolution to 10, so it does not take too long. `10` will give `1 minute` on my computer. But any more than that makes it much much longer than 5 minutes. Refer to [this section](#boundary-box-conditions) to change it. There is a small speedup for luigi.off by a few seconds only. For this low resolution, a lower wendland radius was also found to be better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_luigi()\n",
    "plot_mesh_points(\"data/luigi.off\", k=1, pointsSize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_points_accelerated(\"data/luigi.off\", k=1, pointsSize=1)\n",
    "setup_cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the luigi mesh is now aligned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Extracting the surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to extract the surface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_connected_component(surface_f): \n",
    "    components = igl.facet_components(surface_f)\n",
    "    max_freq_component = np.argmax(np.bincount(components))\n",
    "    max_component = surface_f[components == max_freq_component]\n",
    "    return max_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extracted_surface(name_of_mesh, k=2): \n",
    "    x, T, indicators = plot_mesh_points_accelerated(name_of_mesh, k, False)\n",
    "    sv, sf, _, _ = igl.marching_tets(x, T, indicators, 0)\n",
    "    max_component = get_max_connected_component(sf)\n",
    "    mp.plot(sv, max_component, shading={\"point_size\": 5,\"width\": 800, \"height\": 800})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, bringing up the resolution is a good idea. Maybe 20 to 30 for the cat and 10 for the luigi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform on `cat.off` for the experiments, and report results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: I am unable to get a proper surface out of luigi, perhaps because the resolution is too low. It takes infinitely long for larger resolutions, so I am unable to test. However, the `mesh_points` give a decent idea of the surface that proves my logic is probably not wrong. You can find this in Step 4's [Required Output](#required-output) section. For this reason, I am also unable to properly test a good wendland radius/factor for luigi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_cat()\n",
    "plot_extracted_surface(\"data/cat.off\", k=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general shape of the mesh is there. It doesn't really look like Luigi, but that is expected because the resolution is low. I wasn't able to run it on a higher resolution due to time constraints and my computer not able to handle more than a few minutes before something goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_resolution = resolution\n",
    "previous_wendland_factor = wendlandFactor(1)\n",
    "def wendlandFactor(k): return 0.1\n",
    "resolution = 12\n",
    "plot_extracted_surface(\"data/luigi.off\", k=2)\n",
    "resolution = prev_resolution # change it back\n",
    "def wendlandFactor(k): return previous_wendland_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with `k` (polynomial terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 0, 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: When `k=0`, the surface is not fully captured. However, it is much more smooth-looking. As `k` increases, the surface is more captured, but there are more artifacts and oscillations, which is expected since the polynomial used to fit is more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_extracted_surface(\"data/cat.off\", k=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_extracted_surface(\"data/cat.off\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_extracted_surface(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with wendland radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First refer to [this section](#experiment-with-wendland-radius-using-closestpoints) to see the initial experiments done with some logic. Here, I do more random experiments on the wendland radius with three different values (15%, 20%, 30%) for the sake of seeing the differences fully qualitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: The higher the wendland factor, the more artifacts and oscillations. The lower the wendland factor, the less the surface is captured. 0.2 seemed to work fine with the cat on a qualitative basis, so that is what I kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wendlandFactor(k): return 0.3\n",
    "plot_extracted_surface(\"data/cat.off\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wendlandFactor(k): return 0.20\n",
    "plot_extracted_surface(\"data/cat.off\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wendlandFactor(k): return 0.15\n",
    "plot_extracted_surface(\"data/cat.off\", k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wendlandFactor(k): return 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with grid resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for anisotropic resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea for anisotropic resolutions, as the TA explained, is that you fix one of the dimension's resolutions. Then, you can change the other two dimensions' resolutions to have the same length. So you end up with cubic voxel resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anisotropic_resolutions(bounds, fixedX=None, fixedY=None, fixedZ=None):\n",
    "    x_resolution, y_resolution, z_resolution = fixedX, fixedY, fixedZ\n",
    "    pcbbox_min, pcbbox_max, _, _ = bounds\n",
    "    x_dist, y_dist, z_dist = pcbbox_max - pcbbox_min\n",
    "    if x_resolution is not None: \n",
    "        fixed_voxel_length = x_dist / fixedX\n",
    "        y_resolution = y_dist // fixed_voxel_length\n",
    "        z_resolution = z_dist // fixed_voxel_length\n",
    "    elif y_resolution is not None:\n",
    "        fixed_voxel_length = y_dist / fixedY\n",
    "        x_resolution = x_dist // fixed_voxel_length\n",
    "        z_resolution = z_dist // fixed_voxel_length\n",
    "    elif z_resolution is not None:\n",
    "        fixed_voxel_length = z_dist / fixedZ\n",
    "        x_resolution = x_dist // fixed_voxel_length\n",
    "        y_resolution = y_dist // fixed_voxel_length\n",
    "    return int(x_resolution), int(y_resolution), int(z_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_implicit_function_accelerated(total_points, eps, bounds, spatial_hash, k=2, plot=True, pointsSize=4):\n",
    "    # all the same except for the addition of spatial_hash\n",
    "    pcbbox_min, pcbbox_max, pcbbox_diag, _ = bounds\n",
    "    x_resolution, y_resolution, z_resolution = get_resolution(bounds)\n",
    "    x, T = tet_grid((x_resolution, y_resolution, z_resolution), \n",
    "                pcbbox_min - 0.05 * pcbbox_diag, pcbbox_max + 0.05 * pcbbox_diag)\n",
    "    wendland_radius = wendlandRadius(k, pcbbox_diag)\n",
    "    basis, d = B_k(total_points, k), get_d(total_points, eps)\n",
    "    indicators = np.apply_along_axis(\n",
    "        lambda point: MLS_accelerated(point, total_points, wendland_radius, basis, d, bounds, spatial_hash, k), \n",
    "        axis=1, arr=x)\n",
    "    \n",
    "    colors = np.zeros_like(indicators)\n",
    "    colors[indicators >= 0] = 1\n",
    "    colors[indicators < 0] = -1\n",
    "    if plot: mp.plot(x, c=colors, shading={\"point_size\": pointsSize,\"width\": 800, \"height\": 800})\n",
    "    else: return x, T, indicators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with Anisotropic Resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: Anisotropic resolution in the x direction with 20 is not good. But anisotropic with direction in y and z are good, with y being the best looking surface. It depends on how big x y z are of the bounding box it seems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anisotropic 20 in x \n",
    "def get_resolution(bounds):\n",
    "    return get_anisotropic_resolutions(bounds, fixedX=20)\n",
    "\n",
    "plot_extracted_surface(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anisotropic 20 in y\n",
    "def get_resolution(bounds):\n",
    "    return get_anisotropic_resolutions(bounds, fixedY=20)\n",
    "\n",
    "plot_extracted_surface(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anisotropic 20 in z\n",
    "def get_resolution(bounds):\n",
    "    return get_anisotropic_resolutions(bounds, fixedZ=20)\n",
    "\n",
    "plot_extracted_surface(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Fixed Resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the resolution, the more the surface is captured. However, it takes more time. `resolution=20` is a good balance between time and capturing the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_implicit_function_accelerated(total_points, eps, bounds, spatial_hash, k=2, plot=True, pointsSize=4):\n",
    "    # all the same except for the addition of spatial_hash\n",
    "    pcbbox_min, pcbbox_max, pcbbox_diag, _ = bounds\n",
    "    x, T = tet_grid((resolution,resolution,resolution), \n",
    "                pcbbox_min - 0.05 * pcbbox_diag, pcbbox_max + 0.05 * pcbbox_diag)\n",
    "    wendland_radius = wendlandRadius(k, pcbbox_diag)\n",
    "    basis, d = B_k(total_points, k), get_d(total_points, eps)\n",
    "    indicators = np.apply_along_axis(\n",
    "        lambda point: MLS_accelerated(point, total_points, wendland_radius, basis, d, bounds, spatial_hash, k), \n",
    "        axis=1, arr=x)\n",
    "    \n",
    "    colors = np.zeros_like(indicators)\n",
    "    colors[indicators >= 0] = 1\n",
    "    colors[indicators < 0] = -1\n",
    "    if plot: mp.plot(x, c=colors, shading={\"point_size\": pointsSize,\"width\": 800, \"height\": 800})\n",
    "    else: return x, T, indicators \n",
    "\n",
    "# this is the reset of the function to use fixed resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 10 \n",
    "plot_extracted_surface(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 20\n",
    "plot_extracted_surface(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 30\n",
    "plot_extracted_surface(\"data/cat.off\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Resolution Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for any code tests and additional reports that I did not include in the main sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2 points) In Interpolating and Approximating Implicit Surfaces from Polygon Soup normals are used differently to define the implicit surface. Instead of generating new sample points offset in the positive and negative normal directions, the paper uses the normal to define a linear function for each point cloud point: the signed distance to the tangent plane at the point. Then the values of these linear functions are interpolated by MLS. Implement Section 3.3 of the paper and append to your report a description of the method and how it compares to the original point-value-based approach. Estimate a normal for results obtained with single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the method: The idea is that, instead of the `d` vector we have `[zeros * n, epsilon * n, -epsilon * n]` we have only `[sdf(x)]` for `x` being our initial `n` constraint points, and `sdf` being the signed distance function to the tangent plane at the point. We then have to compute `d` for each point we are considering, and we also need information of the normals. Then we simply apply the same MLS logic as before, with a different `d` vector and different set of constraint points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: As seen after plotting, the plot is similar but a little different. It seems to have some more artifacts but also seems more smooth and no longer as much oscillation. \n",
    "\n",
    "\"Estimate a normal for results obtained with single dataset.\" I am not sure what this is asking, but it sounds like it is just an instruction to get the normals of the surface of each point and to get the signed distance of any point to all such tangents based on the normals. I am doing this in the `get_d_locally` step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_signed_distance(point_x, point_i, normal_i): \n",
    "    return np.dot(normal_i, point_x - point_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d_locally(point, total_points, normals): \n",
    "    d = []\n",
    "    for i in range(len(total_points)): \n",
    "        d.append(compute_signed_distance(point, total_points[i], normals[i]))\n",
    "    return np.array(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passing down the SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveA(x, total_points, normals, radius, basis, closeByPoints): \n",
    "    B = basis\n",
    "    W_matrix = W(x, radius, closeByPoints, total_points)\n",
    "    d_x = get_d_locally(x, total_points, normals)\n",
    "    BtWx = B.T @ W_matrix\n",
    "    \n",
    "    A = BtWxB(B, BtWx)\n",
    "    b = BtWxd(BtWx, d_x)\n",
    "    return np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLS(pt, total_points, normals, radius, basis, k): \n",
    "    # check that there are enough points around it to make a MLS fit \n",
    "    closeByPoints = closest_points(pt, total_points, radius)\n",
    "    if len(closeByPoints) < 2 * polynomialTerms(k): \n",
    "        return large_positive_number # return a large number to indicate that the point is not outside the surface\n",
    "    \n",
    "    # first get coefficients\n",
    "    a = solveA(pt, total_points, normals, radius, basis, closeByPoints)\n",
    "    \n",
    "    # solve for the value \n",
    "    value = getFxValue(pt, a, k)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_implicit_function(total_points, normals, bounds, k=2, plot=True, pointsSize=4): \n",
    "    pcbbox_min, pcbbox_max, pcbbox_diag, _ = bounds\n",
    "    x, T = tet_grid((resolution,resolution,resolution), \n",
    "                pcbbox_min - 0.05 * pcbbox_diag, pcbbox_max + 0.05 * pcbbox_diag)\n",
    "    wendland_radius = wendlandRadius(k, pcbbox_diag)\n",
    "    basis = B_k(total_points, k)\n",
    "    indicators = np.apply_along_axis(\n",
    "        lambda point: MLS(point, total_points, normals, wendland_radius, basis, k), \n",
    "        axis=1, arr=x)\n",
    "    \n",
    "    colors = np.zeros_like(indicators)\n",
    "    colors[indicators >= 0] = 1\n",
    "    colors[indicators < 0] = -1\n",
    "    if plot: mp.plot(x, c=colors, shading={\"point_size\": pointsSize,\"width\": 800, \"height\": 800})\n",
    "    else: return x, T, indicators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new way to get total points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot points - no extraction yet\n",
    "def plot_mesh_points(name_of_mesh, k=2, plot=True, pointsSize=4): \n",
    "    v, _, ni = get_v_f_ni(name_of_mesh)\n",
    "    bounds = mesh_bounds(v)\n",
    "    total_points = v\n",
    "    return plot_implicit_function(total_points, ni, bounds, k, plot, pointsSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extracted_surface(name_of_mesh, k=2): \n",
    "    x, T, indicators = plot_mesh_points(name_of_mesh, k, False)\n",
    "    sv, sf, _, _ = igl.marching_tets(x, T, indicators, 0)\n",
    "    max_component = get_max_connected_component(sf)\n",
    "    mp.plot(sv, max_component, shading={\"point_size\": 5,\"width\": 800, \"height\": 800})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_extracted_surface(\"data/cat.off\", k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Poisson Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting Screenshot: ![Image](./poisson_cat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compared to mine, it is clear that the Poisson Reconstruction is way more smooth and has much less artifacts, seemingly very robust with noisy artifacts. Even with tuning my parameters, I won't be able to achieve that smoothness with that many features represented, while still having barely any artifacts at all. Furthermore, it was extremely fast--- much faster than my MLS implementation, even when it had tried to do Luigi's mesh. Some similarties I noticed is that you also have to tune parameters. For example, below is a screenshot of Luigi's mesh when not tuned properly for Poisson reconstruction. The hat is not captured correctly. However, an advantage of MLS seems to be that it keeps sharp features, whereas Poisson reconstruction seems to always smooth them out and preserve continuity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luigi: ![Image](./poisson_luigi.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
